import streamlit as st
import pandas as pd
import numpy as np


# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆã‚¿ã‚¤ãƒˆãƒ«å¤‰æ›´ï¼‰
st.set_page_config(page_title="å‡¦ç†ã‚¹ã‚³ã‚¢ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ğŸ“", layout="wide")

# å·¦ã«ãƒ­ã‚´ã€å³ã«ã‚¿ã‚¤ãƒˆãƒ«
logo_col, title_col = st.columns([1, 5])
with logo_col:
    # app.py ã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã€Œãƒ­ã‚´_NEW_æ¨ª.pngã€ã‚’ç½®ã„ã¦ãã ã•ã„
    st.image("ãƒ­ã‚´_NEW_æ¨ª.png", use_column_width=True)
with title_col:
    st.title("å‡¦ç†ã‚¹ã‚³ã‚¢ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ğŸ“")

st.markdown(
    """
### ä½¿ã„æ–¹
1. â‘ æ¥­å‹™æ—¥å ± â‘¡æ¥­å‹™å‰²ã‚ŠæŒ¯ã‚Š â‘¢æ¡ˆä»¶ç®¡ç† ã®3ã¤ã®CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰  
2. é›†è¨ˆå¯¾è±¡ã®æœˆã‚’é¸æŠ  
3. å„ã‚¿ãƒ–ã§ã€Œã‚¿ã‚¹ã‚¯åˆ¥ã€ã€Œåˆ©ç”¨è€…åˆ¥ã€ã€Œå…¨ä½“ã€ã‚’ç¢ºèª
"""
)


# ---------- å…±é€šé–¢æ•° ----------

def load_csv(uploaded_file: st.runtime.uploaded_file_manager.UploadedFile):
    """æ—¥æœ¬èªCSVã‚’ã„ã„æ„Ÿã˜ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã‚€"""
    if uploaded_file is None:
        return None

    for enc in ("utf-8", "utf-8-sig", "cp932"):
        try:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding=enc, engine="python")
            return df
        except Exception:
            continue
    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file.name} ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
    return None


def assign_rank(row):
    """ä»•æ§˜ã«åŸºã¥ã æ¥­å‹™ãƒ©ãƒ³ã‚¯(Aã€œE) ã‚’ä»˜ä¸"""
    status = str(row.get("task_status", ""))
    task_name = str(row.get("task_name", ""))
    genre = str(row.get("æ¥­å‹™ã‚°ãƒ«ãƒ¼ãƒ—", ""))
    naigai = str(row.get("æ¡ˆä»¶ç¨®åˆ¥", ""))

    # ãƒ©ãƒ³ã‚¯E
    if (
        status == "ç·´ç¿’"
        or task_name in [
            "ã€ãƒ‡ãƒ¢ã€‘æ¡ç”¨ã‚¹ã‚«ã‚¦ãƒˆé€ä¿¡ãƒ†ã‚¹ãƒˆ",
            "ã€ãƒ‡ãƒ¢ã€‘æ¡ç”¨ã‚¹ã‚«ã‚¦ãƒˆãƒ€ãƒŸãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ä½œæˆæ¥­å‹™",
            "ãã®ä»–",
        ]
        or genre in ["ãã®ä»–", "è»½ä½œæ¥­", "ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”"]
    ):
        return "E"

    # ãƒ©ãƒ³ã‚¯D
    if genre in ["ãƒªã‚¹ãƒˆä½œæˆ", "ãƒ‡ãƒ¼ã‚¿å…¥åŠ›"]:
        return "D"

    # ãƒ©ãƒ³ã‚¯C
    if genre == "ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡":
        return "C"

    # ãƒ©ãƒ³ã‚¯B
    if naigai == "ç¤¾å†…BPO":
        return "B"

    # ãƒ©ãƒ³ã‚¯Aï¼ˆç¤¾å¤–ç³»ã‚’æƒ³å®šï¼‰
    if naigai:
        return "A"

    # ã©ã‚Œã«ã‚‚è©²å½“ã—ãªã„å ´åˆã¯ä»®ã«Eç›¸å½“ã¨ã—ã¦æ‰±ã†ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ï¼‰
    return "E"


RANK_VALUE = {"A": 5, "B": 4, "C": 3, "D": 2, "E": 1}
RANK_ORDER_FOR_USER = {"E": 1, "D": 2, "C": 3, "B": 4, "A": 5}


def calc_deviation_by_task(df: pd.DataFrame, value_col: str, group_col: str = "task_id"):
    """åŒä¸€ã‚¿ã‚¹ã‚¯IDå†…ã§ã®åå·®å€¤ï¼ˆ50Â±10ï¼‰ã‚’è¨ˆç®—"""
    group = df.groupby(group_col)[value_col]
    mean = group.transform("mean")
    std = group.transform("std").replace(0, np.nan)

    deviation = 50 + 10 * (df[value_col] - mean) / std
    deviation = deviation.fillna(50)  # 1äººã®ã¿ / å…¨å“¡åŒå€¤ ã®å ´åˆã¯50ç‚¹å›ºå®š
    return deviation


def compute_all(report_df: pd.DataFrame, assign_df: pd.DataFrame,æ¡ˆä»¶_df: pd.DataFrame, period_str: str):
    """
    3ã¤ã®CSVã‹ã‚‰å…¨ã¦ã®é›†è¨ˆã‚’å®Ÿæ–½ã—ã€
    ãƒ»ã‚¿ã‚¹ã‚¯åˆ¥æ˜ç´°(base_df)
    ãƒ»åˆ©ç”¨è€…åˆ¥é›†è¨ˆ(user_df)
    ãƒ»å…¨ä½“é›†è¨ˆ(summary_dict, org_summary_df)
    ã‚’è¿”ã™
    """

    # ===== â‘  æ¥­å‹™æ—¥å ±ï¼šå¯¾è±¡æœˆã®å‡¦ç†ä»¶æ•°ã‚’é›†è¨ˆ =====
    df_rep = report_df.copy()

    # æ—¥ä»˜ã‚’å¤‰æ›
    df_rep["æ—¥ä»˜"] = pd.to_datetime(df_rep["æ—¥ä»˜"], errors="coerce")

    # å¯¾è±¡æœˆã®ã¿æŠ½å‡ºï¼ˆperiod_str ã¯ 'YYYY-MM'ï¼‰
    target_period = pd.to_datetime(period_str + "-01")
    df_rep = df_rep[df_rep["æ—¥ä»˜"].dt.to_period("M") == target_period.to_period("M")]

    # ã‚¿ã‚¹ã‚¯ID/ä»¶æ•°ã‚’æ­£è¦åŒ–
    df_rep = df_rep[~df_rep["ã‚¿ã‚¹ã‚¯ID"].isna()]
    df_rep["ã‚¿ã‚¹ã‚¯ID"] = df_rep["ã‚¿ã‚¹ã‚¯ID"].astype(int)
    df_rep["ä»¶æ•°"] = pd.to_numeric(df_rep["ä»¶æ•°"], errors="coerce").fillna(0)

    # åˆ©ç”¨è€…Ã—ã‚¿ã‚¹ã‚¯IDã§æœˆé–“ä»¶æ•°
    monthly = (
        df_rep.groupby(["åˆ©ç”¨è€…ã‚³ãƒ¼ãƒ‰", "ã‚¿ã‚¹ã‚¯ID"], as_index=False)["ä»¶æ•°"]
        .sum()
        .rename(columns={"ä»¶æ•°": "monthly_count"})
    )

    # ===== â‘¡ æ¥­å‹™å‰²ã‚ŠæŒ¯ã‚Š Ã— â‘¢æ¡ˆä»¶ç®¡ç† ã‚’çµåˆ =====
    df_assign = assign_df.copy()
    dfæ¡ˆä»¶ = æ¡ˆä»¶_df.copy()

    # æ¡ˆä»¶ç®¡ç†ã‹ã‚‰å¿…è¦ãªåˆ—ã®ã¿ï¼ˆã‚¿ã‚¹ã‚¯ID/ç¤¾å†…å¤–/æ¥­å‹™ã‚°ãƒ«ãƒ¼ãƒ—ï¼‰
    dfæ¡ˆä»¶ = dfæ¡ˆä»¶[["ã‚¿ã‚¹ã‚¯ID", "æ¡ˆä»¶ç¨®åˆ¥", "æ¥­å‹™ã‚°ãƒ«ãƒ¼ãƒ—"]].drop_duplicates()

    # æ¥­å‹™å‰²ã‚ŠæŒ¯ã‚Šã«æ¡ˆä»¶æƒ…å ±ã‚’ä»˜ä¸
    base = df_assign.merge(
        dfæ¡ˆä»¶,
        left_on="task_id",
        right_on="ã‚¿ã‚¹ã‚¯ID",
        how="left",
    )

    # æ—¥å ±é›†è¨ˆï¼ˆæœˆé–“ä»¶æ•°ï¼‰ã‚’ä»˜ä¸
    base = base.merge(
        monthly,
        left_on=["employee_code", "task_id"],
        right_on=["åˆ©ç”¨è€…ã‚³ãƒ¼ãƒ‰", "ã‚¿ã‚¹ã‚¯ID"],
        how="left",
    )

    base["monthly_count"] = base["monthly_count"].fillna(0)

    # ===== â‘¢ ãƒ©ãƒ³ã‚¯ä»˜ä¸ =====
    base["rank"] = base.apply(assign_rank, axis=1)
    base["rank_value"] = base["rank"].map(RANK_VALUE).fillna(0)

    # ===== â‘£ åŒä¸€ã‚¿ã‚¹ã‚¯IDå†…ã§åå·®å€¤ã‚’è¨ˆç®— =====
    base["deviation"] = calc_deviation_by_task(base, "monthly_count", group_col="task_id")

    # ===== â‘¤ å‡¦ç†ã‚¹ã‚³ã‚¢ = ãƒ©ãƒ³ã‚¯å€¤ Ã— å‡¦ç†åå·®å€¤ =====
    base["processing_score"] = base["rank_value"] * base["deviation"]

    # ----- åˆ©ç”¨è€…åˆ¥é›†è¨ˆ -----
    user_df = (
        base.groupby(["employee_code", "user_name", "organization_name"], as_index=False)
        .agg(total_processing_score=("processing_score", "sum"))
    )

    # å„åˆ©ç”¨è€…ãŒæŒã£ã¦ã„ã‚‹æ¥­å‹™ãƒ©ãƒ³ã‚¯ä¸€è¦§ï¼ˆè¡¨ç¤ºç”¨ï¼‰
    rank_list = (
        base.groupby(["employee_code", "user_name", "organization_name"])["rank"]
        .apply(lambda s: ", ".join(sorted(s.dropna().unique())))
        .reset_index(name="task_ranks")
    )
    user_df = user_df.merge(rank_list, on=["employee_code", "user_name", "organization_name"], how="left")

    # è‡ªåˆ†è‡ªèº«ã®æ¥­å‹™ãƒ©ãƒ³ã‚¯ï¼ˆæ‹…å½“æ¥­å‹™ã®ã†ã¡æœ€é«˜ä½ãƒ©ãƒ³ã‚¯ï¼‰
    def best_rank(series: pd.Series):
        s = series.dropna()
        if s.empty:
            return None
        order_values = s.map(RANK_ORDER_FOR_USER)
        return s.iloc[order_values.values.argmax()]

    user_rank = (
        base.groupby(["employee_code", "user_name", "organization_name"])["rank"]
        .apply(best_rank)
        .reset_index(name="user_rank")
    )
    user_df = user_df.merge(user_rank, on=["employee_code", "user_name", "organization_name"], how="left")

    # ----- å…¨ä½“é›†è¨ˆ -----
    overall_mean = user_df["total_processing_score"].mean()
    overall_median = user_df["total_processing_score"].median()

    summary_dict = {
        "overall_mean": overall_mean,
        "overall_median": overall_median,
    }

    # æ‹ ç‚¹åˆ¥ï¼šå¹³å‡ã‚¹ã‚³ã‚¢ & ãƒ©ãƒ³ã‚¯æ§‹æˆï¼ˆäººæ•°æ¯”ï¼‰
    org_base = user_df.copy()
    org_summary = (
        org_base.groupby("organization_name", as_index=False)
        .agg(avg_score=("total_processing_score", "mean"), user_count=("employee_code", "nunique"))
    )

    rank_pivot = (
        org_base.pivot_table(
            index="organization_name",
            columns="user_rank",
            values="employee_code",
            aggfunc=pd.Series.nunique,
            fill_value=0,
        )
        .reset_index()
    )

    # å‰²åˆã«å¤‰æ›
    org_summary = org_summary.merge(rank_pivot, on="organization_name", how="left")
    for r in ["A", "B", "C", "D", "E"]:
        if r in org_summary.columns:
            org_summary[f"ratio_{r}"] = org_summary[r] / org_summary["user_count"]
        else:
            org_summary[f"ratio_{r}"] = 0.0

    return base, user_df, summary_dict, org_summary


# ---------- ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ› ----------

st.sidebar.header("1. CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

# ãƒ©ãƒ™ãƒ«æ–‡è¨€ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«ä¿®æ­£
report_file = st.sidebar.file_uploader("â‘  æ¥­å‹™æ—¥å ±CSV", type=["csv"])
assign_file = st.sidebar.file_uploader("â‘¡ æ¥­å‹™å‰²ã‚ŠæŒ¯ã‚ŠCSV", type=["csv"])
æ¡ˆä»¶_file = st.sidebar.file_uploader("â‘¢ æ¡ˆä»¶ç®¡ç†CSV", type=["csv"])

if not (report_file and assign_file and æ¡ˆä»¶_file):
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ 3ã¤ã®CSV ã‚’ã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# èª­ã¿è¾¼ã¿
df_report = load_csv(report_file)
df_assign = load_csv(assign_file)
df_æ¡ˆä»¶ = load_csv(æ¡ˆä»¶_file)

if df_report is None or df_assign is None or df_æ¡ˆä»¶ is None:
    st.stop()

# ---------- é›†è¨ˆå¯¾è±¡æœˆã®é¸æŠ ----------

# æ—¥å ±ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¹´æœˆä¸€è¦§ã‚’ä½œæˆ
df_report["æ—¥ä»˜"] = pd.to_datetime(df_report["æ—¥ä»˜"], errors="coerce")
valid_dates = df_report["æ—¥ä»˜"].dropna()

if valid_dates.empty:
    st.error("æ—¥å ±ã®ã€æ—¥ä»˜ã€åˆ—ãŒæ­£ã—ãèª­ã¿è¾¼ã‚ã¦ã„ã¾ã›ã‚“ã€‚CSVã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
    st.stop()

periods = sorted(valid_dates.dt.to_period("M").astype(str).unique())
default_period = periods[-1]  # æœ€æ–°æœˆã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

selected_period = st.sidebar.selectbox("2. é›†è¨ˆå¯¾è±¡ã®æœˆ", periods, index=periods.index(default_period))

st.sidebar.success(f"é›†è¨ˆå¯¾è±¡ã®æœˆï¼š{selected_period}")

# ---------- é›†è¨ˆå®Ÿè¡Œ ----------

base_df, user_df, summary, org_summary_df = compute_all(
    df_report, df_assign, df_æ¡ˆä»¶, selected_period
)

# ---------- è¡¨ç¤º ----------

tab1, tab2, tab3 = st.tabs(["ã‚¿ã‚¹ã‚¯åˆ¥å‡¦ç†çŠ¶æ³", "åˆ©ç”¨è€…åˆ¥é›†è¨ˆ", "å…¨ä½“é›†è¨ˆ"])

with tab1:
    st.subheader("ã‚¿ã‚¹ã‚¯åˆ¥å‡¦ç†çŠ¶æ³ï¼ˆæ¥­å‹™å‰²ã‚ŠæŒ¯ã‚Šãƒ™ãƒ¼ã‚¹ï¼‰")
    st.markdown(
        """
- `monthly_count`ï¼šãã®æœˆã®å‡¦ç†ä»¶æ•°  
- `deviation`ï¼šåŒä¸€ã‚¿ã‚¹ã‚¯IDå†…ã§ã®å‡¦ç†ä»¶æ•°ã®åå·®å€¤ï¼ˆå¹³å‡50ãƒ»æ¨™æº–åå·®10ï¼‰  
- `rank`ï¼šæ¥­å‹™ãƒ©ãƒ³ã‚¯ï¼ˆA=ç¤¾å¤– / B=ç¤¾å†… / C=ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡ / D=ãƒªã‚¹ãƒˆä½œæˆãƒ»ãƒ‡ãƒ¼ã‚¿å…¥åŠ› / E=ãã®ä»–ãƒ»ç·´ç¿’ ãªã©ï¼‰  
- `processing_score`ï¼šå‡¦ç†ã‚¹ã‚³ã‚¢ = ãƒ©ãƒ³ã‚¯å€¤(A=5ã€œE=1) Ã— åå·®å€¤
"""
    )
    show_cols = [
        "employee_code",
        "user_name",
        "organization_name",
        "task_id",
        "task_name",
        "task_status",
        "æ¡ˆä»¶ç¨®åˆ¥",
        "æ¥­å‹™ã‚°ãƒ«ãƒ¼ãƒ—",
        "rank",
        "rank_value",
        "monthly_count",
        "deviation",
        "processing_score",
    ]
    show_cols = [c for c in show_cols if c in base_df.columns]
    st.dataframe(base_df[show_cols].sort_values(["organization_name", "user_name", "task_id"]))

with tab2:
    st.subheader("åˆ©ç”¨è€…åˆ¥ é›†è¨ˆçµæœ")
    st.markdown(
        """
- `task_ranks`ï¼šæ‹…å½“ã—ã¦ã„ã‚‹æ¥­å‹™ãƒ©ãƒ³ã‚¯ã®ä¸€è¦§  
- `user_rank`ï¼šãã®åˆ©ç”¨è€…è‡ªèº«ã®æ¥­å‹™ãƒ©ãƒ³ã‚¯ï¼ˆæ‹…å½“æ¥­å‹™ã®ä¸­ã§æœ€ã‚‚é«˜ã„ãƒ©ãƒ³ã‚¯ï¼‰  
- `total_processing_score`ï¼šæ‹…å½“æ¥­å‹™ã®å‡¦ç†ã‚¹ã‚³ã‚¢åˆè¨ˆ
"""
    )
    show_cols = [
        "employee_code",
        "user_name",
        "organization_name",
        "user_rank",
        "task_ranks",
        "total_processing_score",
    ]
    st.dataframe(
        user_df[show_cols].sort_values(
            ["organization_name", "total_processing_score"], ascending=[True, False]
        )
    )

with tab3:
    st.subheader(f"å…¨ä½“é›†è¨ˆï¼ˆ{selected_period}ï¼‰")

    col1, col2 = st.columns(2)
    with col1:
        st.metric("å‡¦ç†ã‚¹ã‚³ã‚¢ å¹³å‡å€¤", f"{summary['overall_mean']:.2f}")
    with col2:
        st.metric("å‡¦ç†ã‚¹ã‚³ã‚¢ ä¸­å¤®å€¤", f"{summary['overall_median']:.2f}")

    st.markdown("### æ‹ ç‚¹åˆ¥ å‡¦ç†ã‚¹ã‚³ã‚¢å¹³å‡ & ãƒ©ãƒ³ã‚¯æ§‹æˆï¼ˆäººæ•°æ¯”ï¼‰")

    # è¡¨ç¤ºç”¨ã«åˆ—ã‚’æ•´ç†
    display_cols = [
        "organization_name",
        "avg_score",
        "user_count",
        "ratio_A",
        "ratio_B",
        "ratio_C",
        "ratio_D",
        "ratio_E",
    ]
    df_disp = org_summary_df[display_cols].copy()
    for c in ["ratio_A", "ratio_B", "ratio_C", "ratio_D", "ratio_E"]:
        df_disp[c] = (df_disp[c] * 100).round(1)  # %

    df_disp = df_disp.rename(
        columns={
            "organization_name": "æ‹ ç‚¹",
            "avg_score": "å¹³å‡ã‚¹ã‚³ã‚¢",
            "user_count": "åˆ©ç”¨è€…æ•°",
            "ratio_A": "Aæ¯”ç‡(%)",
            "ratio_B": "Bæ¯”ç‡(%)",
            "ratio_C": "Cæ¯”ç‡(%)",
            "ratio_D": "Dæ¯”ç‡(%)",
            "ratio_E": "Eæ¯”ç‡(%)",
        }
    )

    st.dataframe(df_disp.sort_values("å¹³å‡ã‚¹ã‚³ã‚¢", ascending=False))
