import streamlit as st
import pandas as pd
import numpy as np


# ---------------------------------------------------------
# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆã‚¿ã‚¤ãƒˆãƒ«ï¼‰
# ---------------------------------------------------------
st.set_page_config(page_title="å‡¦ç†ã‚¹ã‚³ã‚¢ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ğŸ“", layout="wide")

# â˜…ãƒ­ã‚´å‰Šé™¤ï¼šã‚¿ã‚¤ãƒˆãƒ«ã ã‘è¡¨ç¤ºâ˜…
st.title("å‡¦ç†ã‚¹ã‚³ã‚¢ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ğŸ“")

st.markdown(
    """
### ä½¿ã„æ–¹
1. â‘ æ¥­å‹™æ—¥å ± â‘¡æ¥­å‹™å‰²ã‚ŠæŒ¯ã‚Š â‘¢æ¡ˆä»¶ç®¡ç† ã®3ã¤ã®CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰  
2. é›†è¨ˆå¯¾è±¡ã®æœˆã‚’é¸æŠ  
3. å„ã‚¿ãƒ–ã§ã€Œã‚¿ã‚¹ã‚¯åˆ¥ã€ã€Œåˆ©ç”¨è€…åˆ¥ã€ã€Œå…¨ä½“ã€ã‚’ç¢ºèª
"""
)


# ---------------------------------------------------------
# CSV èª­ã¿è¾¼ã¿å…±é€šé–¢æ•°
# ---------------------------------------------------------
def load_csv(uploaded_file):
    """æ—¥æœ¬èªCSVã‚’ã„ã„æ„Ÿã˜ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã‚€"""
    if uploaded_file is None:
        return None

    for enc in ("utf-8", "utf-8-sig", "cp932"):
        try:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding=enc, engine="python")
            return df
        except Exception:
            continue

    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file.name} ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    return None


# ---------------------------------------------------------
# æ¥­å‹™ãƒ©ãƒ³ã‚¯ä»˜ä¸
# ---------------------------------------------------------
def assign_rank(row):
    status = str(row.get("task_status", ""))
    task_name = str(row.get("task_name", ""))
    genre = str(row.get("æ¥­å‹™ã‚°ãƒ«ãƒ¼ãƒ—", ""))
    naigai = str(row.get("æ¡ˆä»¶ç¨®åˆ¥", ""))

    # ãƒ©ãƒ³ã‚¯E
    if (
        status == "ç·´ç¿’"
        or task_name in [
            "ã€ãƒ‡ãƒ¢ã€‘æ¡ç”¨ã‚¹ã‚«ã‚¦ãƒˆé€ä¿¡ãƒ†ã‚¹ãƒˆ",
            "ã€ãƒ‡ãƒ¢ã€‘æ¡ç”¨ã‚¹ã‚«ã‚¦ãƒˆãƒ€ãƒŸãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ä½œæˆæ¥­å‹™",
            "ãã®ä»–",
        ]
        or genre in ["ãã®ä»–", "è»½ä½œæ¥­", "ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå›ç­”"]
    ):
        return "E"

    # ãƒ©ãƒ³ã‚¯D
    if genre in ["ãƒªã‚¹ãƒˆä½œæˆ", "ãƒ‡ãƒ¼ã‚¿å…¥åŠ›"]:
        return "D"

    # ãƒ©ãƒ³ã‚¯C
    if genre == "ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡":
        return "C"

    # ãƒ©ãƒ³ã‚¯B
    if naigai == "ç¤¾å†…BPO":
        return "B"

    # ãƒ©ãƒ³ã‚¯A
    if naigai:
        return "A"

    return "E"


RANK_VALUE = {"A": 5, "B": 4, "C": 3, "D": 2, "E": 1}
RANK_ORDER_FOR_USER = {"E": 1, "D": 2, "C": 3, "B": 4, "A": 5}


# ---------------------------------------------------------
# åå·®å€¤è¨ˆç®—
# ---------------------------------------------------------
def calc_deviation_by_task(df, value_col, group_col="task_id"):
    group = df.groupby(group_col)[value_col]
    mean = group.transform("mean")
    std = group.transform("std").replace(0, np.nan)

    deviation = 50 + 10 * (df[value_col] - mean) / std
    return deviation.fillna(50)


# ---------------------------------------------------------
# å…¨é›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯
# ---------------------------------------------------------
def compute_all(report_df, assign_df, æ¡ˆä»¶_df, period_str):
    df_rep = report_df.copy()

    # æ—¥ä»˜å‡¦ç†
    df_rep["æ—¥ä»˜"] = pd.to_datetime(df_rep["æ—¥ä»˜"], errors="coerce")
    target_period = pd.to_datetime(period_str + "-01")
    df_rep = df_rep[df_rep["æ—¥ä»˜"].dt.to_period("M") == target_period.to_period("M")]

    # æ—¥å ±ã®é›†è¨ˆ
    df_rep = df_rep[~df_rep["ã‚¿ã‚¹ã‚¯ID"].isna()]
    df_rep["ã‚¿ã‚¹ã‚¯ID"] = df_rep["ã‚¿ã‚¹ã‚¯ID"].astype(int)
    df_rep["ä»¶æ•°"] = pd.to_numeric(df_rep["ä»¶æ•°"], errors="coerce").fillna(0)

    monthly = (
        df_rep.groupby(["åˆ©ç”¨è€…ã‚³ãƒ¼ãƒ‰", "ã‚¿ã‚¹ã‚¯ID"], as_index=False)["ä»¶æ•°"]
        .sum()
        .rename(columns={"ä»¶æ•°": "monthly_count"})
    )

    # æ¥­å‹™å‰²ã‚ŠæŒ¯ã‚Šã¨æ¡ˆä»¶ç®¡ç†ã‚’çµåˆ
    df_assign2 = assign_df.copy()
    æ¡ˆä»¶_df2 = æ¡ˆä»¶_df[["ã‚¿ã‚¹ã‚¯ID", "æ¡ˆä»¶ç¨®åˆ¥", "æ¥­å‹™ã‚°ãƒ«ãƒ¼ãƒ—"]].drop_duplicates()

    base = df_assign2.merge(
        æ¡ˆä»¶_df2, left_on="task_id", right_on="ã‚¿ã‚¹ã‚¯ID", how="left"
    ).merge(
        monthly,
        left_on=["employee_code", "task_id"],
        right_on=["åˆ©ç”¨è€…ã‚³ãƒ¼ãƒ‰", "ã‚¿ã‚¹ã‚¯ID"],
        how="left",
    )

    base["monthly_count"] = base["monthly_count"].fillna(0)

    # ãƒ©ãƒ³ã‚¯ä»˜ä¸
    base["rank"] = base.apply(assign_rank, axis=1)
    base["rank_value"] = base["rank"].map(RANK_VALUE)

    # åå·®å€¤
    base["deviation"] = calc_deviation_by_task(base, "monthly_count")

    # å‡¦ç†ã‚¹ã‚³ã‚¢
    base["processing_score"] = base["rank_value"] * base["deviation"]

    # -----------------------------------------------------
    # åˆ©ç”¨è€…åˆ¥é›†è¨ˆ
    # -----------------------------------------------------
    user_df = (
        base.groupby(["employee_code", "user_name", "organization_name"], as_index=False)
        .agg(total_processing_score=("processing_score", "sum"))
    )

    # æ¥­å‹™ãƒ©ãƒ³ã‚¯ä¸€è¦§
    rank_list = (
        base.groupby(["employee_code", "user_name", "organization_name"])["rank"]
        .apply(lambda s: ", ".join(sorted(s.dropna().unique())))
        .reset_index(name="task_ranks")
    )

    user_df = user_df.merge(rank_list, on=["employee_code", "user_name", "organization_name"], how="left")

    # å€‹äººæœ€é«˜ãƒ©ãƒ³ã‚¯
    def best_rank(series):
        s = series.dropna()
        if s.empty:
            return None
        order_values = s.map(RANK_ORDER_FOR_USER)
        return s.iloc[order_values.values.argmax()]

    best_rank_df = (
        base.groupby(["employee_code", "user_name", "organization_name"])["rank"]
        .apply(best_rank)
        .reset_index(name="user_rank")
    )

    user_df = user_df.merge(best_rank_df, on=["employee_code", "user_name", "organization_name"], how="left")

    # -----------------------------------------------------
    # å…¨ä½“é›†è¨ˆ
    # -----------------------------------------------------
    summary = {
        "overall_mean": user_df["total_processing_score"].mean(),
        "overall_median": user_df["total_processing_score"].median(),
    }

    org_summary = (
        user_df.groupby("organization_name", as_index=False)
        .agg(avg_score=("total_processing_score", "mean"), user_count=("employee_code", "nunique"))
    )

    rank_pivot = (
        user_df.pivot_table(
            index="organization_name",
            columns="user_rank",
            values="employee_code",
            aggfunc=pd.Series.nunique,
            fill_value=0,
        )
        .reset_index()
    )

    org_summary = org_summary.merge(rank_pivot, on="organization_name", how="left")

    for r in ["A", "B", "C", "D", "E"]:
        org_summary[f"ratio_{r}"] = org_summary.get(r, 0) / org_summary["user_count"]

    return base, user_df, summary, org_summary


# ---------------------------------------------------------
# CSV ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ---------------------------------------------------------
st.sidebar.header("1. CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

report_file = st.sidebar.file_uploader("â‘  æ¥­å‹™æ—¥å ±CSV", type=["csv"])
assign_file = st.sidebar.file_uploader("â‘¡ æ¥­å‹™å‰²ã‚ŠæŒ¯ã‚ŠCSV", type=["csv"])
æ¡ˆä»¶_file = st.sidebar.file_uploader("â‘¢ æ¡ˆä»¶ç®¡ç†CSV", type=["csv"])

if not (report_file and assign_file and æ¡ˆä»¶_file):
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ 3ã¤ã®CSV ã‚’ã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

df_report = load_csv(report_file)
df_assign = load_csv(assign_file)
df_æ¡ˆä»¶ = load_csv(æ¡ˆä»¶_file)

if df_report is None or df_assign is None or df_æ¡ˆä»¶ is None:
    st.stop()

# ---------------------------------------------------------
# é›†è¨ˆå¯¾è±¡æœˆã®é¸æŠ
# ---------------------------------------------------------
df_report["æ—¥ä»˜"] = pd.to_datetime(df_report["æ—¥ä»˜"], errors="coerce")
valid_dates = df_report["æ—¥ä»˜"].dropna()

if valid_dates.empty:
    st.error("æ—¥å ±ã®ã€æ—¥ä»˜ã€åˆ—ãŒèª­ã¿è¾¼ã‚ã¦ã„ã¾ã›ã‚“ã€‚CSVã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
    st.stop()

periods = sorted(valid_dates.dt.to_period("M").astype(str).unique())
selected_period = st.sidebar.selectbox("2. é›†è¨ˆå¯¾è±¡ã®æœˆ", periods, index=len(periods)-1)

# ---------------------------------------------------------
# é›†è¨ˆå®Ÿè¡Œ
# ---------------------------------------------------------
base_df, user_df, summary, org_summary_df = compute_all(
    df_report, df_assign, df_æ¡ˆä»¶, selected_period
)


# ---------------------------------------------------------
# è¡¨ç¤ºã‚¿ãƒ–
# ---------------------------------------------------------
tab1, tab2, tab3 = st.tabs(["ã‚¿ã‚¹ã‚¯åˆ¥å‡¦ç†çŠ¶æ³", "åˆ©ç”¨è€…åˆ¥é›†è¨ˆ", "å…¨ä½“é›†è¨ˆ"])


# ---------------------------------------------------------
# ã‚¿ã‚¹ã‚¯åˆ¥
# ---------------------------------------------------------
with tab1:
    st.subheader("ã‚¿ã‚¹ã‚¯åˆ¥å‡¦ç†çŠ¶æ³")
    show_cols = [
        "employee_code",
        "user_name",
        "organization_name",
        "task_id",
        "task_name",
        "task_status",
        "æ¡ˆä»¶ç¨®åˆ¥",
        "æ¥­å‹™ã‚°ãƒ«ãƒ¼ãƒ—",
        "rank",
        "rank_value",
        "monthly_count",
        "deviation",
        "processing_score",
    ]
    show_cols = [c for c in show_cols if c in base_df.columns]
    st.dataframe(base_df[show_cols].sort_values(["organization_name", "user_name", "task_id"]))


# ---------------------------------------------------------
# åˆ©ç”¨è€…åˆ¥
# ---------------------------------------------------------
with tab2:
    st.subheader("åˆ©ç”¨è€…åˆ¥ é›†è¨ˆçµæœ")
    show_cols = [
        "employee_code",
        "user_name",
        "organization_name",
        "user_rank",
        "task_ranks",
        "total_processing_score",
    ]
    st.dataframe(
        user_df[show_cols].sort_values(
            ["organization_name", "total_processing_score"], ascending=[True, False]
        )
    )


# ---------------------------------------------------------
# å…¨ä½“é›†è¨ˆ
# ---------------------------------------------------------
with tab3:
    st.subheader(f"å…¨ä½“é›†è¨ˆï¼ˆ{selected_period}ï¼‰")

    col1, col2 = st.columns(2)
    col1.metric("å‡¦ç†ã‚¹ã‚³ã‚¢ å¹³å‡å€¤", f"{summary['overall_mean']:.2f}")
    col2.metric("å‡¦ç†ã‚¹ã‚³ã‚¢ ä¸­å¤®å€¤", f"{summary['overall_median']:.2f}")

    st.markdown("### æ‹ ç‚¹åˆ¥ é›†è¨ˆ")

    display_cols = [
        "organization_name",
        "avg_score",
        "user_count",
        "ratio_A",
        "ratio_B",
        "ratio_C",
        "ratio_D",
        "ratio_E",
    ]

    df_disp = org_summary_df[display_cols].copy()
    for c in ["ratio_A", "ratio_B", "ratio_C", "ratio_D", "ratio_E"]:
        df_disp[c] = (df_disp[c] * 100).round(1)

    df_disp = df_disp.rename(
        columns={
            "organization_name": "æ‹ ç‚¹",
            "avg_score": "å¹³å‡ã‚¹ã‚³ã‚¢",
            "user_count": "åˆ©ç”¨è€…æ•°",
            "ratio_A": "Aæ¯”ç‡(%)",
            "ratio_B": "Bæ¯”ç‡(%)",
            "ratio_C": "Cæ¯”ç‡(%)",
            "ratio_D": "Dæ¯”ç‡(%)",
            "ratio_E": "Eæ¯”ç‡(%)",
        }
    )

    st.dataframe(df_disp.sort_values("å¹³å‡ã‚¹ã‚³ã‚¢", ascending=False))
